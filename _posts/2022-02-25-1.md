---
layout: post
title: Use IndexedDB from the Node.js with TypeScript
subject: Dev
keywords: Node.js, IndexedDB, Build database, TypeScript
---

Modern browsers provide an [IndexedDB](https://developer.mozilla.org/ko/docs/Web/API/IndexedDB_API){:target="_blank" rel="nofollow noopener noreferrer"}
for storing structured data.
IndexedDB is not as powerful as other databases,
but it has the advantage of making relational databases available to client-side.
However, this post will talk about IndexedDB-like database that can be used on server-side, not client-side.

Let's get deep into it.

# Why am I trying to use IndexedDB-like database from the server-side?

On the server-side, there are various databases such as PostgreSQL, MySQL, MongoDB, and so on.
I also wanted to use these databases.
But I don't have a personal server,
and there wasn't good option to use a database for free
because I'm using Heroku's free Dyno.

I'm in trouble.
And I came up with a solution soon.
The solution was to build a database on my own.
I wanted to build a relational database with availability of general querying,
but it was too complicated,
so I decided to build an IndexedDB-like database which has simpler structure.

# Requested features

Before building a database, I thought about what features I needed.
First, it should be possible to store data and to provide the stored data according to the request.
I decided to save the data as a file on the server with JSON format.

Actually, simply storing and reading files in JSON format could serve as similar databases.
However, it was also necessary to consider the case that the size of the data became too vast.
This may not be the case, but suppose that the number of data in a file exceeds 10 million.
To find the data I need, I will use `Array.forEach()` or `Array.filter()` after reading the file.
In this case, I may have to check all 10 million data, and it's really inefficient.

Indexing was needed to solve this inefficient problem.

# Data structure

```
Root database directory
└ Database directory
   └ Store files
```

## Root database directory

This is the root directory where all data related to the database system will be stored.

## Database directory

This is the directory to define the database that contains the set of stores.

## Store files

This is a JSON file containing data array and indexing info.
It has the following structure:

```json
{
  "data": [],
  "indices": {
    "${index-key-hash}": {
      "${index-value-hash}": []
    }
  }
}
```

The `data` field is an array containing non-indexed data.
The database I envisioned checks the index first when getting data.
If data is not found in the index, find in the `data` field.

The `indices` field is an object that stores indexed data.
The `${index-key-hash}` uses encrypted hash value which consist of an array of index keys.
The `${index-value-hash}` uses encrypted hash value which consist of an array of index values.

# Prerequisite

Before starting, install the [lodash](https://lodash.com/){:target="_blank" rel="nofollow noopener noreferrer"}
package and its type definition with the following command.

```bash
npm i lodash && npm i -D @types/lodash
```

# Source code

Since it's not a public project,
I didn't implement some features that may not be needed to me like deleting index or database.
But you can see the basic concept of creating own IndexedDB-like database.

```typescript
import * as fs from 'fs';
import * as path from 'path';
import { cloneDeep } from 'lodash';
import * as crypto from 'crypto';
import { Buffer } from 'buffer';

export interface StoreIndexMap<T> {
  // The value of key property to group the data.
  [k: string]: T[];
}

export interface StoreIndex<T> {
  // The key property to create index.
  [k: string]: StoreIndexMap<T>;
}

/**
 * Concept of store figure:
 * When adding new data, if it has indexed key property, add to `indices` group.
 * If not, add to `data` array.
 * When querying, find the data from `indices` group first, and if not exists,
 * flatten the `indices` group with `data` array to query all data.
 *   -> This will make unexpected performance issue, so
 *   every data is recommended to be indexed.
 */
export interface StoreFigure<T> {
  // The data which aren't indexed.
  data: T[];
  // The data that are indexed.
  indices: StoreIndex<T>;
}

export type AvailableKey<T> = keyof T | (keyof T)[];

// DB root path.
export const DB_PATH = path.join(__dirname, '../db');

const key = Buffer.from(
  '\xaf\xa9\x70\x80\x66\x64\xb7\xd1\x99\x19\xad\xf6\x0b\x94\x69\xbc\x69\x2c\x71\xa0\x77\x57\xf4\xed\xfd\xa0\x1c\x4d\x16\x90\x70\x9f',
  'binary',
);

const iv = Buffer.from(
  '\x6e\x67\xaa\x99\xba\xc5\xa1\x6d\x07\x4f\x1c\xe5\xae\x1e\xc7\x90',
  'binary',
);

const algorithm = 'aes-256-cbc';

/**
 * Encrypt the text to hash string.
 */
function encrypt(text: string): string {
  const cipher = crypto.createCipheriv(algorithm, Buffer.from(key), iv);
  let encrypted = cipher.update(text);
  
  encrypted = Buffer.concat([encrypted, cipher.final()]);
  
  return `${iv.toString('hex')}:${encrypted.toString('hex')}`;
}

/**
 * Decrypt the hash string to text.
 */
function decrypt(text: string): string {
  const data = text.split(':');
  const iv = Buffer.from(data[0], 'hex');
  const encryptedText = Buffer.from(data[1], 'hex');
  const decipher = crypto.createDecipheriv(algorithm, Buffer.from(key), iv);
  let decrypted = decipher.update(encryptedText);
  
  decrypted = Buffer.concat([decrypted, decipher.final()]);
  
  return decrypted.toString();
}

/**
 * Create random key.
 */
function randomKey(): string {
  return Math.random().toString(32).split('.')[1];
}

/**
 * File or directory not exists handler.
 * @param e Error.
 * @param handler This handler only called when error code is `ENOENT`.
 */
function enoentErrorHandler(e: any, handler: () => void): void {
  if (e.code === 'ENOENT') {
    handler();
  } else {
    throw e;
  }
}

export class DiskStore<T> {
  private _data?: StoreFigure<T>;

  // Store path.
  private readonly _path: string;

  constructor(path: string) {
    this._path = path;
    this.rollback();
  }

  /**
   * Get all data from the store.
   */
  getAllData(): T[] {
    const map: any = {};

    Object.keys(this._data.indices).forEach((indexKeysHash) => {
      this._flattenIndexedData(this._data.indices[indexKeysHash]).forEach(
        (data) => {
          if (!map[(data as any).id]) {
            map[(data as any).id] = data;
          }
        },
      );
    });

    this._data.data.forEach((data) => {
      if (!map[(data as any).id]) {
        map[(data as any).id] = data;
      }
    });

    return cloneDeep(Object.keys(map).map((key) => map[key]));
  }

  /**
   * Get data by id.
   * @param id Id to search.
   */
  getDataById(id: string): T {
    let data: T;

    Object.keys(this._data.indices).some((indexKeysHash) => {
      const indexedData = this._flattenIndexedData(
        this._data.indices[indexKeysHash],
      );

      data = indexedData.find((item) => (item as any).id === id);

      if (data) {
        return true;
      }
    });

    // When data wasn't found from the indices, found from the `data` array
    if (!data) {
      data = this._data.data.find((item) => (item as any).id === id);
    }

    // If data wasn't found from the indices and `data` array, then throw error.
    if (!data) {
      throw new Error(`Data is not found by id: '${id}'`);
    }

    return cloneDeep(data);
  }

  /**
   * Get all data by index.
   * @param keys Keys.
   * @param values Values.
   */
  getAllDataByIndex(keys: AvailableKey<T>, values: any[]): T[] {
    const keysArray = this._getIndexKeys(keys);
    const indexKeysHash = encrypt(JSON.stringify(keysArray));
    const indexValuesHash = encrypt(JSON.stringify(values));

    const storeIndexMap = this._data.indices[indexKeysHash];

    if (storeIndexMap) {
      return storeIndexMap[indexValuesHash] || [];
    } else {
      throw new Error(`Index is not exists in store`);
    }
  }

  /**
   * Create new data.
   * @param data Data.
   * @param commit Set `false` to don't commit the changes.
   */
  createData(data: T, commit = true): T {
    // Check the data id.
    // When id is already given, check the duplication from the data.
    if (data.hasOwnProperty('id')) {
      let found: T;

      try {
        found = this.getDataById((data as any).id);
      } catch (e) {
        console.warn(`'id' duplication check as passed.`);
      }

      if (found) {
        throw new Error(`'id' is duplicated!`);
      }
    } else {
      (data as any).id = randomKey();
    }

    const indicesList = this.getIndices();

    // Check the indicesList to guess whether data can be indexed or not.
    // If data is indexable, add to index and set the indexed keys in to `indexed`.
    // The data can be indexed to multiple index.
    // If data isn't indexed to any index, then add to `data` of store.
    if (indicesList.length > 0) {
      const indexed = indicesList.filter((indices) => {
        const values = this._getIndexableValues(data, indices);
        const indexKeysHash = encrypt(JSON.stringify(indices));
        const indexValuesHash = encrypt(JSON.stringify(values));

        if (indices.length === values.length) {
          if (!this._data.indices[indexKeysHash][indexValuesHash]) {
            this._data.indices[indexKeysHash][indexValuesHash] = [];
          }

          this._data.indices[indexKeysHash][indexValuesHash].push(data);

          return true;
        }
      });

      if (indexed.length === 0) {
        this._data.data.push(data);
      }
    } else {
      this._data.data.push(data);
    }

    if (commit) {
      this.commit();
    }

    return cloneDeep(data);
  }

  /**
   * Update the existing data.
   * @param data Data to update.
   * @param commit Set `false` to don't commit the changes.
   */
  updateData(data: T, commit = true): T {
    if (!(data as any).id) {
      throw new Error(`'id' field is required to update data.`);
    }

    // Concept of updating is deleting existing one and creating new one
    // to keep concurrency of indices.
    try {
      this.deleteData((data as any).id, false);
    } catch (e) {
      console.error(e);
      throw new Error(`No data to update by id: '${(data as any).id}'`);
    }

    try {
      this.createData(data, false);
    } catch (e) {
      console.error(e);
      throw new Error(`Failed to update data`);
    }

    if (commit) {
      this.commit();
    }

    return cloneDeep(data);
  }

  /**
   * Delete the existing data.
   * @param id Id to delete.
   * @param commit Set `false` to don't commit the changes.
   */
  deleteData(id: string, commit = true): void {
    const data = this.getDataById(id);
    const indicesList = this.getIndices();
    const indexDeleted = indicesList.filter((indices) => {
      const values = this._getIndexableValues(data, indices);
      const indexKeysHash = encrypt(JSON.stringify(indices));
      const indexValuesHash = encrypt(JSON.stringify(values));

      const list = this._data.indices[indexKeysHash][indexValuesHash] || [];

      if (values.length === indices.length) {
        const deleted = this._deleteDataById(data, list);

        if (list.length === 0) {
          delete this._data.indices[indexKeysHash][indexValuesHash];
        }

        return deleted;
      }
    });

    const deleted = this._deleteDataById(data, this._data.data);

    // The `false` value of `deleted` variable means
    // data is not found by id from the store.
    // So throw error to notice it.
    if (!deleted && indexDeleted.length === 0) {
      throw new Error(`No data to delete by id: '${(data as any).id}'`);
    }

    if (commit) {
      this.commit();
    }
  }

  /**
   * Create index for the store.
   * @param keys Index keys or key.
   * @param commit Set `false` to don't commit the changes.
   */
  createIndex(keys: AvailableKey<T>, commit = true): void {
    const keysArray = this._getIndexKeys(keys);
    const indexKeysHash = encrypt(JSON.stringify(keysArray));

    // If there is no existing index, create new index.
    if (!this._data.indices.hasOwnProperty(indexKeysHash)) {
      this._data.indices[indexKeysHash] = {};

      // Loop the previous indexed data to index to newly created index.
      Object.keys(this._data.indices).forEach((_indexKeysHash) => {
        const data = this._flattenIndexedData(
          this._data.indices[_indexKeysHash],
        );

        data.forEach((item) => this._addDataToIndex(keysArray, item));
      });

      // Index the data to newly created index.
      // Indexed data will be removed from the `data`.
      this._data.data = this._data.data.filter(
        (item) => !this._addDataToIndex(keysArray, item),
      );

      if (commit) {
        this.commit();
      }
    }
  }

  /**
   * Get the whole available indices from the store.
   */
  getIndices(): (keyof T)[][] {
    return Object.keys(this._data.indices).map((key) => {
      const decrypted = decrypt(key);

      return JSON.parse(decrypted);
    }) as (keyof T)[][];
  }

  /**
   * Commit the changes.
   */
  commit(): void {
    fs.writeFileSync(this._path, JSON.stringify(this._data), {
      encoding: 'utf8',
    });
  }

  /**
   * Rollback to last committed data.
   */
  rollback(): void {
    const contents = fs.readFileSync(this._path, {encoding: 'utf8'});

    if (contents) {
      this._data = JSON.parse(contents);
    } else {
      this._data = {
        data: [],
        indices: {},
      };
    }
  }

  /**
   * Add data to index.
   * @param indices Index keys.
   * @param data Data.
   * @return The state of added to index.
   */
  private _addDataToIndex(indices: (keyof T)[], data: T): boolean {
    const values = this._getIndexableValues(data, indices);
    const indexKeysHash = encrypt(JSON.stringify(indices));
    const indexValuesHash = encrypt(JSON.stringify(values));

    // If `item` has all keys for index, then add to index map.
    if (values.length === indices.length) {
      if (!this._data.indices[indexKeysHash][indexValuesHash]) {
        this._data.indices[indexKeysHash][indexValuesHash] = [];
      }

      if (
        !this._data.indices[indexKeysHash][indexValuesHash].some(
          (item) => (item as any).id === (data as any).id,
        )
      ) {
        this._data.indices[indexKeysHash][indexValuesHash].push(data);
        return true;
      }
    }

    return false;
  }

  /**
   * Delete the data by id from the data list.
   * @param data Data to delete.
   * @param list Data list.
   */
  private _deleteDataById(data: T, list: T[] = []): boolean {
    let deleted = false;
    const searchedIndex = this._searchIndexById(data, list);

    if (searchedIndex !== -1) {
      list.splice(searchedIndex, 1);
      deleted = true;
    }

    return deleted;
  }

  /**
   * Search the data by id from the data list.
   * @param data Data to search.
   * @param list Data list.
   */
  private _searchIndexById(data: T, list: T[] = []): number {
    return list.findIndex((item) => (item as any).id === (data as any).id);
  }

  /**
   * Flatten the indexed data as array.
   * @param storeIndexMap The index map.
   */
  private _flattenIndexedData(storeIndexMap?: StoreIndexMap<T>): T[] {
    const data: T[] = [];

    if (storeIndexMap) {
      Object.keys(storeIndexMap).map((key) => {
        data.push(...storeIndexMap[key]);
      });
    }

    return data;
  }

  /**
   * Get available keys as an array.
   * @param keys Keys.
   */
  private _getIndexKeys(keys: AvailableKey<T>): (keyof T)[] {
    // Make sure `keys` to be an array.
    let keysArray: (keyof T)[];

    if (keys instanceof Array) {
      keysArray = keys;
    } else {
      keysArray = [keys];
    }

    return keysArray;
  }

  /**
   * Get the indexable values from the data.
   * @param data Data.
   * @param keysArray The keys.
   */
  private _getIndexableValues(data: T, keysArray: (keyof T)[]): any[] {
    const valuesArray: any[] = [];

    // Check whether `data` has key property or not.
    keysArray.forEach((key) => {
      if (data.hasOwnProperty(key)) {
        valuesArray.push(data[key as any]);
      }
    });

    return valuesArray;
  }
}

export class DiskDb {
  // Db path.
  private readonly _path: string;

  constructor(path: string) {
    this._path = path;
  }

  /**
   * Get or create new store.
   * @param name Store name.
   */
  getOrCreateStore<T>(name: string): DiskStore<T> {
    const storePath = path.join(this._path, `${name}.json`);

    try {
      fs.statSync(storePath);
    } catch (e) {
      const initialData: StoreFigure<T> = {
        data: [],
        indices: {},
      };

      enoentErrorHandler(e, () =>
        fs.writeFileSync(storePath, JSON.stringify(initialData), {
          encoding: 'utf8',
        }),
      );
    }

    return new DiskStore<T>(storePath);
  }

  /**
   * Delete the store file.
   * @param name Store name.
   */
  deleteStore(name: string): void {
    fs.unlinkSync(path.join(this._path, `${name}.json`));
  }
}

/**
 * Db util to manage common db system.
 */
export class DbUtil {
  /**
   * Get or create the db.
   * @param name Db name.
   */
  static getOrCreateDb(name: string): DiskDb {
    try {
      fs.statSync(DB_PATH);
    } catch (e) {
      enoentErrorHandler(e, () => fs.mkdirSync(DB_PATH));
    }

    const dbPath = path.join(DB_PATH, name);

    try {
      fs.statSync(dbPath);
    } catch (e) {
      enoentErrorHandler(e, () => fs.mkdirSync(dbPath));
    }

    return new DiskDb(dbPath);
  }
}

```

# Usage

## Create database and store

```typescript
// This will create the root database directory and `my-db` directory. 
const myDb = DBUtil.getOrCreateDb('my-db');

// This will create `my-store.json` in the `my-db` directory.
// The `getOrCreateStore()` method is similar to open connection for database.
// Every contents of `my-store.json` will be stored in memory
// when creating `DiskStore` instance for `my-store`.
const myStore = myDb.getOrCreateStore('my-store');
```

## Get, create, update, delete data

```typescript
interface Child {
  id?: string | number;
  name: string;
  age: number;
}

const myDb = DBUtil.getOrCreateDb('my-db');
const myStore = myDb.getOrCreateStore<Child>('my-store');

// This will create the data and save to `my-store`.
// The `id` field is automatically created when creating new data.
// Creating automatically committed.
const { id } = myStore.createData<Child>({
  name: 'John',
  age: 4,
});

// It's same with above, but `id` is manually created.
// In this case, you can use your own `id` if it's not duplicated.
// You can also use second paramter to prevent auto commit.
// With this feature, you can mock the transaction of other databases.
myStore.createData<Child>({
  id: 1,
  name: 'Jane',
  age: 7,
}, false);

// Call commit after all changes done.
myStore.commit();

// Get `John` data with his `id` and update his age to `10`.
const john = myStore.getDataById(id);

john.age = 10;

// Make sure that you don't have any uncommitted data
// before calling method without second parameter.
// This will commit previous changes as well.
myStore.updateData(john);

// When deleting data, only the `id` is needed.
// So, this will delete the data of `Jane`.
myStore.deleteData(1);
```

# How does indexing work?

When creating an index,
if there are some data that need to be indexed in `data` field,
then remove those from the `data` field and create index with `${index-keys-hash}` and `${index-values-hash}`.

So, how the `${index-keys-hash}` and `${index-values-hash}` are created?
Let's assume that you have the following store named with `employees`.

```json
{
  "data": [
    {
      "id": "1",
      "name": "John",
      "depart": "Development"
    },
    {
      "id": "2",
      "name": "Jane",
      "depart": "Development"
    },
    {
      "id": "3",
      "name": "Jake",
      "depart": "Design"
    }
  ],
  "indices": {}
}
```

Then you write the code to create index for this store.

```typescript
const db = DBUtil.getOrCreateDb('db');
const employees = db.getOrCreateStore('employees');

// Create the index to `employees` store.
// You can set parameter to ['depart'] as well. 
employees.createIndex('depart');
```

It will create index for `depart` field.
The `${index-keys-hash}` is encrypted hash code of `['depart']` JSON string.
The data will be grouped by `${index-values-hash}` in `${index-keys-hash}`.
The `${index-values-hash}` is values array of index fields.
So the above data will be grouped by `['Development']` and `['Design']`.

After indexing, `emplyees` store looks like below:

```json
{
  "data": [],
  "indices": {
    "${index-keys-hash}": {
      "${index-values-hash-for-development}": [
        {
          "id": "1",
          "name": "John",
          "depart": "Development"
        },
        {
          "id": "2",
          "name": "Jane",
          "depart": "Development"
        }
      ],
      "${index-values-hash-for-design}": [
        {
          "id": "3",
          "name": "Jake",
          "depart": "Design"
        }
      ]
    }
  }
}
```

When getting data, the store searches `indices` first to avoid inefficiency.

# Conclusion

As you may have noticed,
this is actually quite different from IndexedDB in a web browser.
But I believe it can provide you some guidance on how to implement your own IndexedDB in Node.js.
